<!DOCTYPE html>
<html lang="en"><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
   <meta name="description" content="
paper

Introduction: Memory Barriers: a Hardware View for Software Hackers



0x0 why we need memory barrier
In short, because reordering memory references allows much better performance, and so memory barriers are needed to force ordering in things like synchronization primitives whose correct operation depends on ordered memory references.
0x1 Cache Structure

0x11 some cases of cache miss(not important)
The cache miss means that the CPU will have to wait (or be “stalled”) for hundreds of cycles while the item is fetched from memory.">  

  <title>
    
      MESI AND MEMORY_BARRIER: paper reading
    
  </title>


  <link rel="shortcut icon" type="image/x-icon" href="/" />
  
  
  
  <link rel="stylesheet" href="//localhost:1313/css/main.900100e9dbee2d56c58fac8bb717037cae7e26a9c36c29d2ff587bdd65f0cbbe510b41d81a3bb234919cdfdc7550d786b2fab70c8fc507772d732fe097106d12.css" integrity="sha512-kAEA6dvuLVbFj6yLtxcDfK5&#43;JqnDbCnS/1h73WXwy75RC0HYGjuyNJGc39x1UNeGsvq3DI/FB3ctcy/glxBtEg==" />
  
</head>
<body a="auto">
        <main class="page-content" aria-label="Content">
            <div class="w">
<a href="/">..</a>


<article>
    <p class="post-meta">
        <time datetime="2024-06-16 01:12:36 &#43;0800 CST">
            2024-06-16
        </time>
    </p>

    <h1>MESI AND MEMORY_BARRIER: paper reading</h1>

    
        <aside >
            <nav id="TableOfContents">
  <ul>
    <li><a href="#0x0-why-we-need-memory-barrier">0x0 why we need memory barrier</a></li>
    <li><a href="#0x1-cache-structure">0x1 <strong>Cache Structure</strong></a>
      <ul>
        <li><a href="#0x11-some-cases-of-cache-missnot-important">0x11 some cases of cache miss(not important)</a></li>
      </ul>
    </li>
    <li><a href="#0x2-cache-coherence-protocols">0x2 Cache-Coherence Protocols</a>
      <ul>
        <li><a href="#0x21-four-state-mesi-states">0x21 Four state: MESI States</a></li>
        <li><a href="#0x22-messages-between-the-cpusand-memory-mesi-protocol-messages">0x22 Messages between the cpus(and memory): MESI Protocol Messages</a></li>
        <li><a href="#0x23-state-machine-mesi-state-diagram">0x23 State Machine: MESI State Diagram</a></li>
      </ul>
    </li>
    <li><a href="#0x3-optimize-1-stores-result-in-unnecessary-stalls">0x3 Optimize 1: Stores Result in Unnecessary Stalls</a>
      <ul>
        <li><a href="#0x31-store-forwarding-problem">0x31: Store Forwarding problem</a></li>
        <li><a href="#0x32-store-buffers-and-memory-barriers">0x32 Store Buffers and Memory Barriers</a></li>
      </ul>
    </li>
    <li><a href="#0x4-optimize-2-store-sequences-result-in-unnecessary-stalls">0x4 Optimize 2: Store Sequences Result in Unnecessary Stalls</a>
      <ul>
        <li><a href="#0x42-invalidate-queues-and-invalidate-acknowledge">0x42 Invalidate Queues and Invalidate Acknowledge</a></li>
        <li><a href="#0x43-invalidate-queues-and-memory-barriers">0x43 Invalidate Queues and Memory Barriers</a></li>
      </ul>
    </li>
    <li><a href="#0x5-summary-read-and-write-memory-barriers">0x5 Summary: Read and Write Memory Barriers</a></li>
  </ul>
</nav>
        </aside>
    

    <ul>
<li>paper
<ul>
<li>Introduction: <a href="https://raw.githubusercontent.com/mobilephone724/blog_pictures/master/memory_barrier_withMarginNotes.2024_06_16_1718472482.pdf">Memory Barriers: a Hardware View for Software Hackers</a></li>
</ul>
</li>
</ul>
<h2 id="0x0-why-we-need-memory-barrier">0x0 why we need memory barrier</h2>
<p>In short, because <strong>reordering memory references allows much better performance</strong>, and so memory barriers are needed to force ordering in things like synchronization primitives whose <strong>correct operation depends on ordered memory references</strong>.</p>
<h2 id="0x1-cache-structure">0x1 <strong>Cache Structure</strong></h2>
<p><img src="https://raw.githubusercontent.com/mobilephone724/blog_pictures/master/Untitled.2024_06_17_1718631318.png" alt="Untitled"></p>
<h3 id="0x11-some-cases-of-cache-missnot-important">0x11 some cases of cache miss(not important)</h3>
<p>The cache miss means that the CPU will have to wait (or be “stalled”) for hundreds of cycles while the item is fetched from memory.</p>
<ul>
<li>
<p><strong>capacity miss</strong>: After some time, the CPU’s cache will fill, and sub- sequent misses will likely need to eject an item from the cache in order to make room for the newly fetched item</p>
</li>
<li>
<p><strong>associativity miss</strong>: occur in set-associative caches.</p>
<blockquote>
<p>An &ldquo;associativity cache miss&rdquo; refers to a specific type of cache miss that can occur in set-associative caches.</p></blockquote>
<blockquote>
<p>In a set-associative cache, the cache memory is divided into sets, and each set contains multiple cache lines (or cache blocks). When the CPU needs to access data in memory, it first checks the cache to see if the data is present. The cache lookup is done by first identifying the set that the data would be stored in, and then searching through the multiple cache lines within that set to see if the data is present.</p></blockquote>
<blockquote>
<p>An associativity cache miss occurs when the data the CPU needs is not found in any of the cache lines within the identified set. This means the CPU has to go to main memory to fetch the data, which is slower than finding it in the cache.</p></blockquote>
<blockquote>
<p>The number of cache lines per set is called the &ldquo;associativity&rdquo; of the cache. Caches with higher associativity (more cache lines per set) generally have lower associativity cache miss rates, but they are also more complex and expensive to implement. The goal is to find the right balance of associativity to minimize cache misses without making the cache design overly complex.</p></blockquote>
</li>
<li>
<p><strong>write miss</strong>: Before a given CPU writes to that data item, it must first cause it to be removed, or “invalidated”, from other CPUs’ caches. Once this invalidation has completed, the CPU may safely modify the data item. If the data item was present in this CPU’s cache, but was read- only, this process is termed a “write miss”.</p>
</li>
</ul>
<p>cache structure: one cache address can store two(or more?) sets of data.</p>
<p><img src="https://raw.githubusercontent.com/mobilephone724/blog_pictures/master/Untitled%201.2024_06_17_1718631325.png" alt="Untitled"></p>
<h2 id="0x2-cache-coherence-protocols">0x2 Cache-Coherence Protocols</h2>
<h3 id="0x21-four-state-mesi-states">0x21 Four state: MESI States</h3>
<p>The four types of states represent the state of a cache line in one cpu.</p>
<p>Here, we use “I” to represent the cpu.</p>
<ul>
<li><strong>modified</strong>:
<ul>
<li>I have changed the value in private cache and not written it back to memory.</li>
<li>Others  can’t access the memory until change their states(signal me).</li>
</ul>
</li>
<li><strong>exclusive</strong>:
<ul>
<li>I haven’t changed the value in private cache. (But may change it later, transfer to <strong>modified</strong> state)</li>
<li>Others can’t access the memory until change their states(signal me).</li>
</ul>
</li>
<li><strong>shared</strong>
<ul>
<li>Others can read the memory without consulting me.</li>
</ul>
</li>
<li><strong>invalid:</strong>
<ul>
<li>the cache line holds no data.</li>
</ul>
</li>
</ul>
<h3 id="0x22-messages-between-the-cpusand-memory-mesi-protocol-messages">0x22 Messages between the cpus(and memory): MESI Protocol Messages</h3>
<ul>
<li><strong>Read:</strong> a request for reading  a line</li>
<li><strong>Read Response</strong>: The line data for a previous read. Either of memory or other cpu.</li>
<li><strong>Invalidate</strong>: invalidate the line in <strong>all other cpus</strong></li>
<li><strong>Invalidate Acknowledge:</strong> successful response to a previous <strong>Invalidate</strong> message</li>
<li><strong>Read Invalidate</strong>: a <strong>atomic combination</strong> of “read” and “invalidate”. Requires both a “read response” and a set of “in- validate acknowledge” messages in reply.</li>
<li><strong>Writeback:</strong> write a line to memory</li>
</ul>
<h3 id="0x23-state-machine-mesi-state-diagram">0x23 State Machine: MESI State Diagram</h3>
<p><img src="https://raw.githubusercontent.com/mobilephone724/blog_pictures/master/Untitled%202.2024_06_17_1718631330.png" alt="Untitled"></p>
<p>Transitions are explained below:</p>
<ul>
<li>(a): write back to memory</li>
<li>(b): modify the data in cache</li>
<li>(c): I haven’t written back to memory but another cpu requests it (and will change it). So I return the value in cache and invalidate the private one without writing back to memory</li>
<li>(d): I want to change a cache, so I emit a “invalidate” to other cpus. Now all others have acknowledge me, so I read and change my private cache.</li>
<li>(e): Similar to “(d)”, but don’t need to read in memory.</li>
<li>(f): Similar to (c), I haven’t written back to memory but another cpu requests it (but will not change it), so I return my private value.</li>
<li>(g): Similar to (f)</li>
<li>(h): similar to “(d)”, but don’t modify it now</li>
<li>(i): similar to “(c)”, but don’t need to return my private value since that in memory is still the newest.</li>
<li>(j): Similar to “(d)”</li>
<li>(k): read in memory( or other cpu)</li>
<li>(l): receive a “invalidate” message</li>
</ul>
<p>Examples are in the paper.</p>
<h2 id="0x3-optimize-1-stores-result-in-unnecessary-stalls">0x3 Optimize 1: Stores Result in Unnecessary Stalls</h2>
<p>Consider to modify a cache that isn’t in <strong>modified</strong> or <strong>exclusive</strong> state.</p>
<p><img src="https://raw.githubusercontent.com/mobilephone724/blog_pictures/master/Untitled%203.2024_06_17_1718631337.png" alt="Untitled"></p>
<ul>
<li><strong>Problem</strong>: there is no real reason to force CPU 0 to stall for so long — after all, regardless of what data happens to be in the cache line that CPU 1 sends it, CPU 0 is going to unconditionally overwrite it.</li>
<li><strong>Solution</strong>: Add “store buffers” between each CPU and its cache
<ul>
<li>CPU0 write to its store buffer immediately</li>
<li><strong>When CPU0 is acknowledged, the data will be moved from the store buffer to the cache line</strong></li>
</ul>
</li>
</ul>
<h3 id="0x31-store-forwarding-problem">0x31: Store Forwarding problem</h3>
<p><img src="https://raw.githubusercontent.com/mobilephone724/blog_pictures/master/Untitled%204.2024_06_17_1718631343.png" alt="Untitled"></p>
<p>Thinking of the program below:</p>
<ul>
<li>CPU0 has value b</li>
<li>CPU1 has value a = 0 in exclusive mode</li>
</ul>
<pre tabindex="0"><code>a = 1;
b = a + 1;
assert(b == 2);
</code></pre><p>step1: cpu0 invalidate cpu1 with “a” , change private cache line to 1, and write it to store buffer.</p>
<p>step2: cpu0 receive the value “a” from cpu1. The value is 0, and it’s stored in private cache.(Note that the value in the store buffer is 1)</p>
<p>step3: cpu0 executes “b = a + 1”, load “a” from cache, and its value is 0</p>
<p>step4: cpu0 store the value of “b” to cache, whose value is 1</p>
<p>step5: cpu0 move the value of “a” from store buffer(1) to cache(0)</p>
<p>step6: CPU0 executes assert(b==2), which fails.</p>
<p>The problem is that we have two copies of “a”, one in the cache and the other in the store buffer.</p>
<hr>
<p>The hardware guys took pity and implemented “store forwarding”, where <strong>each CPU refers to (or “snoops”) its store buffer as well as its cache when performing loads</strong></p>
<p><strong>In other words, a given CPU’s stores are directly forwarded to its subsequent loads, without hav- ing to pass through the cache.</strong></p>
<p><img src="https://raw.githubusercontent.com/mobilephone724/blog_pictures/master/Untitled%205.2024_06_17_1718631351.png" alt="Untitled"></p>
<h3 id="0x32-store-buffers-and-memory-barriers">0x32 Store Buffers and Memory Barriers</h3>
<p>Think of the program below</p>
<pre tabindex="0"><code>void foo(void)
{
  a=1;
  b=1;
}

void bar(void) {
  while (b == 0) continue;
  assert(a == 1);
}
</code></pre><ul>
<li>cpu0 executes foo
<ul>
<li>own “b”</li>
</ul>
</li>
<li>cpu1 executes bar
<ul>
<li>own “a”</li>
</ul>
</li>
</ul>
<hr>
<p><img src="https://raw.githubusercontent.com/mobilephone724/blog_pictures/master/Untitled%206.2024_06_17_1718631356.png" alt="Untitled"></p>
<p>The problem is that, cpu1 reads “a” before being acknowledged that other cpus have changed it. Although CPU0 can continue to execute before writing it to stored buffer, but CPU1 doesn’t know that.</p>
<p>The hardware designers cannot help directly here, since the <strong>CPUs have no idea which variables are related, let alone how they might be related</strong></p>
<p>Therefore, the hardware designers provide <strong>memory-barrier</strong> instructions to allow the software to tell the CPU about such relations. The program fragment must be updated to contain the memory barrier:</p>
<pre tabindex="0"><code>void foo(void)
{
  a=1;
  smp_mb();
  b=1;
}

void bar(void)
{
  while (b == 0) continue;
  assert(a == 1);
}
</code></pre><p>The memory barrier <code>smp_mb()</code> will cause the CPU to flush its store buffer before applying subsequent stores to their cache lines. The CPU could either</p>
<ul>
<li>simply stall until the store buffer was empty before proceeding, or</li>
<li>it could only use the store buffer to hold subsequent stores until all of the prior entries in the store buffer had been applied.
<ul>
<li>This is to prevent other cpus from getting the subsequent value before getting the prior entries</li>
</ul>
</li>
</ul>
<p>So that, CPU0 will</p>
<ul>
<li>wait for the “invalidate acknowledge” message of “a” before executing “b=1;”</li>
</ul>
<p>or</p>
<ul>
<li>(1)while executing <code>smp_mb</code> ,marks all current store-buffer entries (namely, the a=1)</li>
<li>(2) while executing “b=1”, only stores it store buffer.</li>
<li>(3) wait “invalidate acknowledge” of “a”</li>
<li>(4) store the value of b in stored buffer and send a “invalidate” message</li>
</ul>
<h2 id="0x4-optimize-2-store-sequences-result-in-unnecessary-stalls">0x4 Optimize 2: Store Sequences Result in Unnecessary Stalls</h2>
<ol>
<li>Once the stored buffer is full or a memory barrier is encountered, the CPU must once again wait for invalidations to complete in order to drain its store buffer before it can continue executing</li>
<li>invalidate acknowledge messages can take so long: they must ensure that the corre- sponding cache line is actually invalidated, and this invalidation can be delayed if the cache is busy, for example, if the CPU is intensively loading and storing data, all of which resides in the cache.</li>
</ol>
<p>However, the CPU need not actually invalidate the cache line before sending the acknowledgement.</p>
<h3 id="0x42-invalidate-queues-and-invalidate-acknowledge">0x42 Invalidate Queues and Invalidate Acknowledge</h3>
<p><img src="https://raw.githubusercontent.com/mobilephone724/blog_pictures/master/Untitled%207.2024_06_17_1718631364.png" alt="Untitled"></p>
<p><strong>A CPU with an invalidate queue may acknowledge an invalidate message as soon as it is placed in the queue, instead of having to wait until the corresponding line is actually invalidated.</strong></p>
<h3 id="0x43-invalidate-queues-and-memory-barriers">0x43 Invalidate Queues and Memory Barriers</h3>
<p>Thinking of the following code:</p>
<pre tabindex="0"><code>void foo(void)
{
  a=1;
  smp_mb();
  b=1;
}

void bar(void)
{
  while (b == 0) continue;
  assert(a == 1);
}
</code></pre><ul>
<li>CPU0:
<ul>
<li>execute foo</li>
<li>a is shared state</li>
<li>b is exclusive</li>
</ul>
</li>
<li>CPU1:
<ul>
<li>execute bar</li>
</ul>
</li>
</ul>
<p><img src="https://raw.githubusercontent.com/mobilephone724/blog_pictures/master/Untitled%208.2024_06_17_1718631370.png" alt="Untitled"></p>
<ul>
<li>Once again, the CPU designers cannot do much about this situation</li>
<li>However, the memory-barrier instructions can interact with the invalidate queue.</li>
</ul>
<p>When a given CPU executes a memory barrier, it marks all the entries currently in its invalidate queue, and forces <strong>any subsequent load to wait until all marked entries have been applied to the CPU’s cache</strong>.</p>
<pre tabindex="0"><code>void foo(void)
{
  a=1;
  smp_mb();
  b=1;
}

void bar(void)
{
  while (b == 0) continue;
  smp_mb();
  assert(a == 1);
}
</code></pre><hr>
<p>So that, CPU0 will</p>
<ul>
<li>(1) executes the <code>smp_mb()</code>, marking the entry in its invalidate queue.</li>
<li>(2) start executing the assert(a==1), but a is in the invalidate queue, CPU 1 must stall this load until that entry in the invalidate queue has been applied.</li>
</ul>
<h2 id="0x5-summary-read-and-write-memory-barriers">0x5 Summary: Read and Write Memory Barriers</h2>
<p>In the previous section, memory barriers were used to mark entries in both the store buffer and the inval- idate queue. <strong>But in our code fragment, foo() had no reason to do anything with the invalidate queue, and bar() similarly had no reason to do anything with the store queue.</strong></p>
<p>Many CPU architectures therefore provide weaker memory-barrier instructions that do only one or the other of these two.</p>
<ul>
<li>read memory barrier:
<ul>
<li>marks only the invalidate queue</li>
<li>forces any subsequent <strong>load</strong> to wait until all marked entries have been applied from the <strong>invalidate queue</strong></li>
</ul>
</li>
<li>write memory barrier:
<ul>
<li>marks only the store buffer.</li>
<li>only use the store buffer to hold subsequent <strong>stores</strong> until all of the prior entries in the <strong>store buffer</strong> had been applied.</li>
</ul>
</li>
</ul>
<pre tabindex="0"><code>void foo(void)
{
  a=1;
  smp_wmb();
  b=1;
}

void bar(void)
{
  while (b == 0) continue;
  smp_rmb();
  assert(a == 1);
}
</code></pre>
</article>

                
    
    
        Thanks for <a href="https://github.com/hanwenguo/hugo-theme-nostyleplease">https://github.com/hanwenguo/hugo-theme-nostyleplease</a>
    


            </div>
        </main>
    </body>
</html>
