<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>PGVECTOR AND VECTOR DATABASE | PaperMod</title>
<meta name="keywords" content="">
<meta name="description" content="序言 pgvector是一个向量搜索（根据近似度）的插件，用来加速AKNN（approximate nearest neighbor）。 PASE中提到，向量ANN算法包括4类
tree-based algorithms KD-Tree RTree quantization-based algorithms IVFFlat IVFADC IMI graph based algorithms HNSW NSG SSG hash-base algorithms LSH pgvector 包括两个算法，IVFFlat 和 HNSW，后续内容将以这两个算法的内容及其实现展开。 IVFFlat 概览 IVFFlat 算法主要包括以下几个步骤
索引构建阶段 使用 KMeans 将数据集划分成多个簇(cluster) 查询阶段 通过每个簇的中心点（向量是高维的点）获取N个最近的簇 遍历这N个簇的所有点，从中找到最近的K个点 算法介绍 基础算法kmeans reference k-means clustering - Wikipedia 算法目标：选取K个中心点，使得数据集中的所有点到其最近的中心点“距离”之和最近，以平方和距离为例：
Given a set of observations $(x_1, x_2, \dots, x_n)$, where each observation is a $d$-dimensional real vector, k-means clustering aims to partition the $n$ observations into $k$ ($\leq n$) sets $S = {S_1, S_2, \dot, S_k}$ so as to minimize the within-cluster sum of squares (WCSS).">
<meta name="author" content="mobilephone724">
<link rel="canonical" href="http://localhost:1313/article/pgvector/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.45e028aa8ce0961349adf411b013ee39406be2c0bc80d4ea3fc04555f7f4611a.css" integrity="sha256-ReAoqozglhNJrfQRsBPuOUBr4sC8gNTqP8BFVff0YRo=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:1313/apple-touch-icon.png">
<link rel="mask-icon" href="http://localhost:1313/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="http://localhost:1313/article/pgvector/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
  

<meta property="og:url" content="http://localhost:1313/article/pgvector/">
  <meta property="og:site_name" content="PaperMod">
  <meta property="og:title" content="PGVECTOR AND VECTOR DATABASE">
  <meta property="og:description" content="序言 pgvector是一个向量搜索（根据近似度）的插件，用来加速AKNN（approximate nearest neighbor）。 PASE中提到，向量ANN算法包括4类
tree-based algorithms KD-Tree RTree quantization-based algorithms IVFFlat IVFADC IMI graph based algorithms HNSW NSG SSG hash-base algorithms LSH pgvector 包括两个算法，IVFFlat 和 HNSW，后续内容将以这两个算法的内容及其实现展开。 IVFFlat 概览 IVFFlat 算法主要包括以下几个步骤
索引构建阶段 使用 KMeans 将数据集划分成多个簇(cluster) 查询阶段 通过每个簇的中心点（向量是高维的点）获取N个最近的簇 遍历这N个簇的所有点，从中找到最近的K个点 算法介绍 基础算法kmeans reference k-means clustering - Wikipedia 算法目标：选取K个中心点，使得数据集中的所有点到其最近的中心点“距离”之和最近，以平方和距离为例：
Given a set of observations $(x_1, x_2, \dots, x_n)$, where each observation is a $d$-dimensional real vector, k-means clustering aims to partition the $n$ observations into $k$ ($\leq n$) sets $S = {S_1, S_2, \dot, S_k}$ so as to minimize the within-cluster sum of squares (WCSS).">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="article">
      <meta property="og:image" content="http://localhost:1313/images/papermod-cover.png">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://localhost:1313/images/papermod-cover.png">
<meta name="twitter:title" content="PGVECTOR AND VECTOR DATABASE">
<meta name="twitter:description" content="序言 pgvector是一个向量搜索（根据近似度）的插件，用来加速AKNN（approximate nearest neighbor）。 PASE中提到，向量ANN算法包括4类
tree-based algorithms KD-Tree RTree quantization-based algorithms IVFFlat IVFADC IMI graph based algorithms HNSW NSG SSG hash-base algorithms LSH pgvector 包括两个算法，IVFFlat 和 HNSW，后续内容将以这两个算法的内容及其实现展开。 IVFFlat 概览 IVFFlat 算法主要包括以下几个步骤
索引构建阶段 使用 KMeans 将数据集划分成多个簇(cluster) 查询阶段 通过每个簇的中心点（向量是高维的点）获取N个最近的簇 遍历这N个簇的所有点，从中找到最近的K个点 算法介绍 基础算法kmeans reference k-means clustering - Wikipedia 算法目标：选取K个中心点，使得数据集中的所有点到其最近的中心点“距离”之和最近，以平方和距离为例：
Given a set of observations $(x_1, x_2, \dots, x_n)$, where each observation is a $d$-dimensional real vector, k-means clustering aims to partition the $n$ observations into $k$ ($\leq n$) sets $S = {S_1, S_2, \dot, S_k}$ so as to minimize the within-cluster sum of squares (WCSS).">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "较长的专题文章",
      "item": "http://localhost:1313/article/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "PGVECTOR AND VECTOR DATABASE",
      "item": "http://localhost:1313/article/pgvector/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "PGVECTOR AND VECTOR DATABASE",
  "name": "PGVECTOR AND VECTOR DATABASE",
  "description": "序言 pgvector是一个向量搜索（根据近似度）的插件，用来加速AKNN（approximate nearest neighbor）。 PASE中提到，向量ANN算法包括4类\ntree-based algorithms KD-Tree RTree quantization-based algorithms IVFFlat IVFADC IMI graph based algorithms HNSW NSG SSG hash-base algorithms LSH pgvector 包括两个算法，IVFFlat 和 HNSW，后续内容将以这两个算法的内容及其实现展开。 IVFFlat 概览 IVFFlat 算法主要包括以下几个步骤\n索引构建阶段 使用 KMeans 将数据集划分成多个簇(cluster) 查询阶段 通过每个簇的中心点（向量是高维的点）获取N个最近的簇 遍历这N个簇的所有点，从中找到最近的K个点 算法介绍 基础算法kmeans reference k-means clustering - Wikipedia 算法目标：选取K个中心点，使得数据集中的所有点到其最近的中心点“距离”之和最近，以平方和距离为例：\nGiven a set of observations $(x_1, x_2, \\dots, x_n)$, where each observation is a $d$-dimensional real vector, k-means clustering aims to partition the $n$ observations into $k$ ($\\leq n$) sets $S = {S_1, S_2, \\dot, S_k}$ so as to minimize the within-cluster sum of squares (WCSS).",
  "keywords": [
    
  ],
  "articleBody": "序言 pgvector是一个向量搜索（根据近似度）的插件，用来加速AKNN（approximate nearest neighbor）。 PASE中提到，向量ANN算法包括4类\ntree-based algorithms KD-Tree RTree quantization-based algorithms IVFFlat IVFADC IMI graph based algorithms HNSW NSG SSG hash-base algorithms LSH pgvector 包括两个算法，IVFFlat 和 HNSW，后续内容将以这两个算法的内容及其实现展开。 IVFFlat 概览 IVFFlat 算法主要包括以下几个步骤\n索引构建阶段 使用 KMeans 将数据集划分成多个簇(cluster) 查询阶段 通过每个簇的中心点（向量是高维的点）获取N个最近的簇 遍历这N个簇的所有点，从中找到最近的K个点 算法介绍 基础算法kmeans reference k-means clustering - Wikipedia 算法目标：选取K个中心点，使得数据集中的所有点到其最近的中心点“距离”之和最近，以平方和距离为例：\nGiven a set of observations $(x_1, x_2, \\dots, x_n)$, where each observation is a $d$-dimensional real vector, k-means clustering aims to partition the $n$ observations into $k$ ($\\leq n$) sets $S = {S_1, S_2, \\dot, S_k}$ so as to minimize the within-cluster sum of squares (WCSS). Formally, the objective is to find: 算法过程： 我们可以很容易的证明目标函数是关于$S$的凸函数 Given an initial set of $k$ means $m_1^{1}, \\dots , m_k^{(1)}$ (see below), the algorithm proceeds by alternating between two steps:\nAssignment step: Assign each observation to the cluster with the nearest mean: where each $x_p$is assigned to exactly one $S^{t}$, even if it could be assigned to two or more of them.\nUpdate step: Recalculate means (centroids) for observations assigned to each cluster.\nkmeans 优化篇 上述算法虽然简洁，但计算上复杂度高。在pgvector的IVFFlat实现中，使用了一些优化算法，主要是如下两篇论文：\nUsing Triangle Inequality: 使用三角不等式减少两点间距离的计算次数 KMeans++ :使用随机点的选取技巧来提高收敛速度和准确率 Using the Triangle Inequality to Accelerate k-Means (aaai.org) kMeansPP-soda.pdf (stanford.edu) Using Triangle Inequality 思路：\n在高维向量中，计算一次两点之间的距离的代价较高。 根据一些朴素的思想，假如使用的距离函数满足三角不等式$d(a,b) \\leq d(a,c) + d(b,c)$，那么在一次kmeams迭代中，如果点 x 距其中心点 c(x) 的距离很近，而 c(x) 距另一个中心点 c(y) 的距离很远，那么c(y)必然不是x 的中心点，这样就可以避免一次计算。 根据三角不等式可以推出\nLet x be a point and let b and c be centers. If $d(b, c) \u003e 2d(x,b)$, then $d(x,c) \\geq d(x,b)$ Let x be a point and let b and c be centers, then $d(x,c) \\geq \\mathrm{max} {0,d(x,b)-d(b,c)}$ 根据上述定理，在Kmeans迭代期间，维护一些状态，即可减少计算量 过程如\n使用三角不等式优化Kmeans\nKMeans++ 论文中的数学分析很多，其主要目的为：通过在初始化的时候选取恰当的中心点，减少迭代次数。方法为： 假设向量的全集为$X={x_1,x_2,\\dots,x_n}\\subset \\mathbb{R}^d$ ,$D(x)$ 表示点 $x$ 到其当前中心点的距离\n从$X$ 中随机选择一个点$c_1$ 以$\\frac{D(x’)}{\\sum_{x\\in X}D(x)}$ 的概率选择$x’$为$c_i$ 重复上一步直到我们选择了 $k$ 个中心点， 使用标准的k-means算法进行后续处理 实现介绍 page representation Key functions index build 索引构建分为以下几个步骤\n计算中心点 构建元信息页（‘meta page’） 构建中心点页（‘centerid pages’） 构建数据页（‘data pages’） ivfflatbuild BuildIndex InitBuildState ComputeCenters CreateMetaPage CreateListPages CreateEntryPages FreeBuildState 计算中心点 实现上，没有扫描所有的行以计算中心点，而是“采样”一些block。 会选择$ncenter \\times 50$ 作为采样block的数量 ComputeCenters SampleRows /* The number of target samples is the number of centers times 50 */ numSamples = buildstate-\u003elists * 50; buildstate-\u003esamples = VectorArrayInit(numSamples, buildstate-\u003edimensions); BlockSampler_Init \u003e provides algorithm for block level sampling of a relation as discussed on pgsql-hackers 2004-04-02 (subject \"Large DB\") Since we know the total number of blocks in advance, we can use the straightforward Algorithm S from Knuth 3.4.2, rather than Vitter's algorithm. reservoir_init_selection_state while (BlockSampler_HasMore(\u0026buildstate-\u003ebs)) table_index_build_range_scan: callback=SampleCallback IvfflatKmeans # Do as kmeans algrithm if (samples-\u003elength \u003c= centers-\u003emaxlen) QuickCenters(index, samples, centers); else ElkanKmeans(index, samples, centers); SampleCallback AddSample if (samples-\u003elength \u003c targsamples) VectorArraySet else if (buildstate-\u003erowstoskip \u003c 0) rowstoskip = reservoir_get_next_S #skip some future samples else k = sampler_random_fract VectorArraySet\t# replace a old with this one randomly 构建元信息页 CreateMetaPage # info about meta information IvfflatNewBuffer IvfflatInitRegisterPage IvfflatCommitBuffer 构建中心点页 当一个页的剩余空间不够时，使用字段nextblkno指向下一个页\ntypedef struct IvfflatPageOpaqueData { BlockNumber nextblkno; uint16\tunused; uint16\tpage_id;\t/* for identification of IVFFlat indexes */ }\tIvfflatPageOpaqueData; CreateListPages # info about center infomation foreach sampled vector if (PageGetFreeSpace \u003c listSize) # we need more free space to store the vector IvfflatAppendPage newbuf = IvfflatNewBuffer newpage = GenericXLogRegisterBuffer IvfflatPageGetOpaque old_page-\u003enext = this_page IvfflatInitPage PageAddItem # copy this point to the page 构建数据页 CreateEntryPages # omit parallel optimization here AssignTuples # Scan table for tuples to index tuplesort_performsort InsertTuples for (int i = 0; i \u003c buildstate-\u003ecenters-\u003elength; i++) buf = IvfflatNewBuffer(index, forkNum); # add new page for each data page list startPage = BufferGetBlockNumber(buf); # the first page number foreach tuple in this list: if (PageGetFreeSpace(page) \u003c itemsz) # append page IvfflatAppendPage(index, \u0026buf, \u0026page, \u0026state, forkNum); PageAddItem() IvfflatUpdateList(); # update the first page record of the center page index scan begin scan ivfflatbeginscan IvfflatGetMetaPageInfo(index, \u0026lists, \u0026dimensions); # Get lists and dimensions from metapage get tupele ivfflatgettuple if (first) # try to get the first tuple GetScanLists # find 'probe' centers that are closest while (BlockNumberIsValid(nextblkno)) # search all list pages if (distance \u003c maxDistance) # omit probe here for easier understanding scanlist = (IvfflatScanList *) pairingheap_remove_first(so-\u003elistQueue); pairingheap_add(so-\u003elistQueue, \u0026scanlist-\u003eph_node); maxDistance = ((IvfflatScanList *) pairingheap_first(so-\u003elistQueue))-\u003edistance; GetScanItems # find closest items in the above centers while (!pairingheap_is_empty(so-\u003elistQueue)) # for each center while (BlockNumberIsValid(searchPage)) # for each block in the data list foreach (tuple) tuplesort_puttupleslot HNSW 概览 HNSW 算法主要包括以下几个步骤\n索引构建 构建层级邻近图 每一层都是邻近图 —— 每个点都记录它最近的几个点 高一层的图是低一层图的缩略图 —— 只有低一层图的部分点 ——，最低一层的图有全部点的信息。 查询阶段，对于目标点$p$ 对于每一层图： 维护一个图中距点$p$最近的点集合$S$，依次从候选点集合$C$中选取一个元素$c$：如果$c$的邻居$neighbor(c)$比$S$中距$p$最远的点$s$距$p$更近，即$d(neighbor(c), p) \u003c d(s,c)$ ，则用$neighbor(c)$替换集合$S$中的点$s$，并将$s$加入到候选集合$C$中。重复以上步骤直到$|c| = 0$ 从高层图向底层图搜索，使用高层图的结果$S$作为低层图$S$和$C$的初始值。 算法介绍 一下顺序只是为了便于理解，不代表论文发布顺序。更多细节可参考论文。\nNSW —— HNSW的起源? NSW可以视为邻近图，每个点维护至多$K$个距离其最近的点，此时HNSW退化为只有一层的特殊情况。\nNSW的构建 构建NSW的算法如下（此处忽略边角情况以方便理解\nINPUT: a set of points S OUTPUT: graph G BUILD_LAYER(S) G = [] # Insert each point into the graph FOREACH point IN S: ---------- INSERT_POINT(graph, point) neighbors[] = select_one_random(G) candidate[] = neighbors[] visited_points[] = neighbors[] # Code in this WHILE loop is to find the neighbors of the point # in current graph WHILE (!candidate.empty()) nearest_candidate = candidate.pop_nearest(point) furthest_neighbor = neighbors.get_furthest(point) # no candidate can b closer IF (distant(nearest_candidate, point) \u003e distant(furthest_neighbor, point)) break; # This candidate is great, but what about its neighbors? FOREACH candidate_neighbor in nearest_candidate.neighbors() IF (visited_points.has(candidate_neighbor)) continue visited_points.append(candidate_neighbor) # the furthest one can be changed furthest_neighbor = neighbors.get_furthest(point) # The neighbor of this candidate is also great, its neighbors # can also be candidates IF (distant(candidate_neighbor, point) \u003c distant(furthest_neighbor, point)) candidate.append(candidate_neighbor) neighbors.append(candidate_neighbor) IF (neighbors.size() \u003e MAX_NEIGHBORS) neighbors.pop_furthest(point) # Now we have found the neighbors, add a bidirection connections # between the each neighbor and the point FOREACH this_neighbor in neighbors add_bidirection_direction(this_neighbor, point) # Since the neighbor has one more connection, we may need # to shrink. This is a point to optimize. Read paper for detail. IF this_neighbor.neighbors().size() \u003e MAX_NEIGHBORS this_neighbor.drop_longest_connection() # All points have been added RETURN G NSW的搜索 OUTPUT: graph G, point P RETURN K nearest neighbors SEARCH_LAYER(G, p, K) candidates = select_one_random(G) visited_points = candidates # LOOP until we have K stable points WHILE TRUE candidates_old = candidates FOREACH candidate in candidates FOREACH neighbor in candidate.neighbors() if (visited_points.has(neighbor)) continue visited_points.add(neighbor) furthest_candidate = candidates.get_furthest(point) IF (distant(neighbor, P) \u003c distant(furthest_candidate, P) || candidates.size() \u003c K) candidates.add(neighbor) IF (candidates.size() \u003e K) candidates.pop_furthest(P) IF candidates_old == candidates BREAK RETURN candidates HNSW —— NSW的进化 显然，上述过程最大的问题之一为：\n对于图的构建：每新加入一个点，都需要从一个随机点开始搜索它的邻居。 对于图的搜索：需要从一个随机点开始搜索。 以上两点导致，NSW算法搜索了很多无用的点。 H(hierarchy)NSW 为解决这个问题，从NSW图（layer=0）中选出部分点，再构建一个缩略的NSW图（layer=1）。在搜索的时候，只需要从layer=1的图中搜索出一个粗略结果，将该结果用于layer=0搜索过程中的初始化，即可大量减少无用的搜索。同理，层数也不一定只有2层，可以有更多。 （这个思想在科研中似乎经常使用:先得出一个粗略的结果，再进一步精细化） 为了构建一个这样的图，我们在插入一个点时。\nINPUT: point P, a series of NSW graph G[] cur_layer = -ln(unif(0, 1)) * MAX_LAYER # for layer upper than current layer, just get a candidate FOR l from MAX_LAYER to cur_layer + 1 closest_points = SEARCH_LAYER(G[l], P, 1, candidates = closest_point) # insert into each layer from top to bottom of the below layers FOR l from cur_layer to 0 closest_points = SEARCH_LAYER(G[l], P, 1, candidates = closest_points) INSERT_POINT(graph, P, neighbors = closest_points) 同理在搜索时\nINPUT: point P, a series of NSW graph G[] cur_layer = P.layer # for layer upper than current layer, just get a candidate FOR l from MAX_LAYER to cur_layer + 1 closest_points = SEARCH_LAYER(G[l], P, 1, candidates = closest_point) # for layer leq than current layer, just get a candidate FOR l from cur_layer to 0 closest_points = SEARCH_LAYER(G[l], P, 1, candidates = closest_point) return closest_points PGVECTOR中的算法实现 INSERT /* * Algorithm 1 from paper: update graph by inserting an element * Parms: * @element: element to insert * @entryPoint: the initial entry point * @index? * @procinfo * @collation * @m: same as \"M\" in algo(number of established connections) */ HnswInsertElement(HnswElement element, HnswElement entryPoint, Relation index, FmgrInfo *procinfo, Oid collation, int m, int efConstruction, bool existing) level = element-\u003elevel; q = PointerGetDatum(element-\u003evec) # fill entry point list with the initial one ep = list_make1(HnswEntryCandidate(entryPoint,)) # for layers upper than the element's level for (int lc = entryLevel; lc \u003e= level + 1; lc--) # only get the nearest element now w = HnswSearchLayer() ep = w; # for the below layers for (int lc = level; lc \u003e= 0; lc) # search for top efConstruction nearest ones w = HnswSearchLayer(efConstruction) lw = w # get neighbors neighbors = SelectNeighbors(lw, lm, lc, procinfo, collation, NULL); # add connection # Is this different from paper? # bidirectional vs single directional # shrink directions or not shrink AddConnections() foreach(lc2, neighbors) a-\u003eitems[a-\u003elength++] = *((HnswCandidate *) lfirst(lc2)); search layer /* * Algorithm 2 from paper: search this layer with specifiyed enter points to * return \"ef\" closest neighbors * Parms: * @q: same as algo * @ep: enter points * @ef: count of closest neighbors * @lc: layer number * @index: * @procinfo: * @collation: * @inserting: * @skipElement: */ List * HnswSearchLayer(Datum q, List *ep, int ef, int lc, Relation index, FmgrInfo *procinfo, Oid collation, int m, bool inserting, HnswElement skipElement) v = NULL. # visited points C = NULL # set of candidates, nearer first W = NULL # dynamic found nearest neighbors # for each candidate in enter points foreach(lc2, ep) hc = (HnswCandidate *) lfirst(lc2); # HNSW candidates v.add(hc) C.add(hc) W.add(hc) # loop until no more candidates while (!C.empty()) c = C.pop_nearest() # for each neighbor \"e\" in the nearest candicate \"c\" neighborhood = \u0026c-\u003eelement-\u003eneighbors[lc]; for (int i = 0; i \u003c neighborhood-\u003elength; i++) # neighbor e HnswCandidate *e = \u0026neighborhood-\u003eitems[i]; v.add(e) DO # continue if visited # f is the furthest element in dynamic neighbors f = W.furthest() # find a good neighbor who is closer to q than the worst one in W if (DISTANT(e, q) \u003c DISTANT(f, q) || wlen \u003c ef) ec = e # neighbor of ec can also be the candidates C.add(ec) # add ec to W to promote the lower bound W.add(ec) # clean W if it's too large if (skipElement == NULL || list_length(e-\u003eelement-\u003eheaptids) != 0) wlen++; /* No need to decrement wlen */ if (wlen \u003e ef) W.pop_furthest return W pairing heap 配对堆 - OI Wiki (oi-wiki.org)\ninsert($\\mathrm{log}n$) random_select($\\mathrm{log} n$) select_min($\\mathrm{log} n$) delete_min($\\mathrm{log} n$) select neighbors /* * Algorithm 4: select neighbors starting with specified candidates * PARAMS: * @c : candidates * @m : number of neighbors to return * @lc: layer number * @ * * NOTES: * extendCandidates = false * keepPrunedConnections = true * pruned */ static List * SelectNeighbors(List *c, int m, int lc, FmgrInfo *procinfo, Oid collation, HnswCandidate * *pruned) r = NULL # results---returning neighbors w = c # working candidates wd = NULL; # discarded candidates; # Since we don't extend candidates, if the starting candidates isn't enought # just return. if (list_length(w) \u003c= m) return w # loop untils no more working candidate or enought neighbors while (length(w) \u003e 0 \u0026\u0026 length(r) \u003c m) *e = llast(w); # get the nearest candidates closer = CheckElementCloser(e, r, lc, procinfo, collation); if(closer) r.append(e) else wd.append(e) # loop until discarded candidates are empty or enough neighbors while (!wd.empty() \u0026\u0026 length(r) \u003c m) r.append(wd.pop_nearest()) prune = wd.nearest() return r data structure typedef struct HnswElementData { List\t*heaptids; uint8\tlevel; uint8\tdeleted; HnswNeighborArray *neighbors; BlockNumber blkno; OffsetNumber offno; OffsetNumber neighborOffno; BlockNumber neighborPage; Vector\t*vec; }\tHnswElementData; typedef struct HnswCandidate { HnswElement element; float\tdistance; }\tHnswCandidate; typedef struct HnswNeighborArray { int\tlength; HnswCandidate *items; }\tHnswNeighborArray; 底层实现中的问题 论文中的图是双向连接，而pgvector实现的是单向连接 pgvector中插入新向量时，没有更新其邻居的连接。（这么低级的问题有待验证） page representation vector database 调研 qdrant Vector databases are optimized for storing and querying these high-dimensional vectors efficiently, and they often using specialized data structures and indexing techniques such as Hierarchical Navigable Small World (HNSW) – which is used to implement Approximate Nearest Neighbors – and Product Quantization, among others.\n算法与存储 qdrant使用 hnsw 算法\nA key feature of Qdrant is the effective combination of vector and traditional indexes. It is essential to have this because for vector search to work effectively with filters, having vector index only is not enough. In simpler terms, a vector index speeds up vector search, and payload indexes speed up filtering.\npayload 索引仅用于过滤，我们关注向量索引部分\nQdrant currently only uses HNSW as a vector index.\nAll data within one collection is divided into segments. Each segment has its independent vector and payload storage as well as indexes.\n附录 trianlge-inequality-Kmeans 维护的状态： lower bound $l(x,c)$ of $d(x,c)$ for each point $x$ and center $c$ each time $d(x,c)$ is computed, set $l(x,c)=d(x,c)$ $c(x)= \\mathrm{argmin}_cd(x,c)$ get its center for each point $x$ upper bound $u(x)$ of $d(x,c)$ for each point $x$, indicating the upper bound of $x$ to its center $r(x)$ is a boolean value indicate whether $u(x, c)$ is out of date 过程： initialization compute $d(x,c)$ for each point $x$ and each center $c$, which means $l(x,c)$ is computed too $u(x)=\\mathrm{min}_c(d,c)$ for each point $x$ repeate until convergence: For each pair of centers $c$ and $c’$ , compute $d(c,c’)$, this is to compute $s(c)=1/2\\min_{c’\\neq c}d(c,c’)$ . So we get the distance to the nearest center of each center identify all point $x$ such that $u(x) \\le s(c(x))$ .If the point is so near to its center, its center can’t be changed in this iteration. See lemma 1 For each remaining point $x$ and centers $c$ such that $c\\neq c(x)$ (not the current center) and $u(x)\u003el(x,c)$ (upper bound to current center greater than lower bound of this center) and $u(x)\u003e\\frac{1}{2}d(c(x),c)$(upper bound to current center greater than half of the two centers distant, See lemma 1) iterm 2 and 3 means $u(x)$ may be too big DO: If $r(x)$ , compute$d(x, c(x))$ and set $r(x)=false$, else $d(x,c(x))=u(x)$ if $u(x)\u003el(x,c)$ and $u(x)\u003e\\frac{1}{2}d(c(x),c)$ then (same as the above) compute $d(x,c)$, if $d(x,c) \u003c d(x,c(x))$ then assign $c(x)=c$ (update center) For each center $c$ , let $m(c)$ be the new mean point For each point $x$ and center $c$, assign $l(x,c)=\\max{l(x,c)-d(c,m(c))}$ (update lower bound by lemma 2) For each point x, assign $u(x)=u(x) + d(m(c(x)),c(x))$ (update lower bound by lemma 2 ) and $r(x)=true$ Replace each center $c$ by $m(c)$ 采样算法 Knuth’s algorithm S 算法描述： Select $n$ items from a set of $M$ iems with equal probility for $M \\geq n$ 实现 samples = set[0:n-1] for i in (n, M) with prob = n/i: samples[random()%n] = set[i] 参考文档 Knuth’s algorithm S - Rosetta Code 。\n社区讨论 [PostgreSQL: Re: GENERAL] Large DB\n后记 pg官方的新闻：PostgreSQL: pgvector 0.5.0 Released! 。pgvector在社区的热度不小 ",
  "wordCount" : "2238",
  "inLanguage": "en",
  "image": "http://localhost:1313/images/papermod-cover.png","datePublished": "0001-01-01T00:00:00Z",
  "dateModified": "0001-01-01T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "mobilephone724"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://localhost:1313/article/pgvector/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "PaperMod",
    "logo": {
      "@type": "ImageObject",
      "url": "http://localhost:1313/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/" accesskey="h" title="PaperMod (Alt + H)">PaperMod</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://localhost:1313/article" title="article">
                    <span>article</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/archives" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="https://github.com/adityatelange/hugo-PaperMod/wiki/" title="WiKi">
                    <span>WiKi</span>&nbsp;
                    <svg fill="none" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round"
                        stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12">
                        <path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"></path>
                        <path d="M15 3h6v6"></path>
                        <path d="M10 14L21 3"></path>
                    </svg>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="http://localhost:1313/">Home</a>&nbsp;»&nbsp;<a href="http://localhost:1313/article/">较长的专题文章</a></div>
    <h1 class="post-title entry-hint-parent">
      PGVECTOR AND VECTOR DATABASE
    </h1>
    <div class="post-meta">11 min&nbsp;·&nbsp;mobilephone724&nbsp;|&nbsp;<a href="https://github.com/adityatelange/hugo-PaperMod/tree/exampleSite/content/article/pgvector.md" rel="noopener noreferrer" target="_blank">Suggest Changes</a>

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#%e5%ba%8f%e8%a8%80" aria-label="序言">序言</a></li>
                <li>
                    <a href="#ivfflat" aria-label="IVFFlat">IVFFlat</a><ul>
                        
                <li>
                    <a href="#%e6%a6%82%e8%a7%88" aria-label="概览">概览</a></li>
                <li>
                    <a href="#%e7%ae%97%e6%b3%95%e4%bb%8b%e7%bb%8d" aria-label="算法介绍">算法介绍</a><ul>
                        
                <li>
                    <a href="#%e5%9f%ba%e7%a1%80%e7%ae%97%e6%b3%95kmeans" aria-label="基础算法kmeans">基础算法kmeans</a></li>
                <li>
                    <a href="#kmeans-%e4%bc%98%e5%8c%96%e7%af%87" aria-label="kmeans 优化篇">kmeans 优化篇</a><ul>
                        
                <li>
                    <a href="#using-triangle-inequality" aria-label="Using Triangle Inequality">Using Triangle Inequality</a></li>
                <li>
                    <a href="#kmeans" aria-label="KMeans&#43;&#43;">KMeans++</a></li></ul>
                </li></ul>
                </li>
                <li>
                    <a href="#%e5%ae%9e%e7%8e%b0%e4%bb%8b%e7%bb%8d" aria-label="实现介绍">实现介绍</a><ul>
                        <ul>
                        
                <li>
                    <a href="#page-representation" aria-label="page representation">page representation</a></li></ul>
                    
                <li>
                    <a href="#key-functions" aria-label="Key functions">Key functions</a><ul>
                        
                <li>
                    <a href="#index-build" aria-label="index build">index build</a><ul>
                        
                <li>
                    <a href="#%e8%ae%a1%e7%ae%97%e4%b8%ad%e5%bf%83%e7%82%b9" aria-label="计算中心点">计算中心点</a></li>
                <li>
                    <a href="#%e6%9e%84%e5%bb%ba%e5%85%83%e4%bf%a1%e6%81%af%e9%a1%b5" aria-label="构建元信息页">构建元信息页</a></li>
                <li>
                    <a href="#%e6%9e%84%e5%bb%ba%e4%b8%ad%e5%bf%83%e7%82%b9%e9%a1%b5" aria-label="构建中心点页">构建中心点页</a></li>
                <li>
                    <a href="#%e6%9e%84%e5%bb%ba%e6%95%b0%e6%8d%ae%e9%a1%b5" aria-label="构建数据页">构建数据页</a></li></ul>
                </li>
                <li>
                    <a href="#index-scan" aria-label="index scan">index scan</a><ul>
                        
                <li>
                    <a href="#begin-scan" aria-label="begin scan">begin scan</a></li>
                <li>
                    <a href="#get-tupele" aria-label="get tupele">get tupele</a></li></ul>
                </li></ul>
                </li></ul>
                </li></ul>
                </li>
                <li>
                    <a href="#hnsw" aria-label="HNSW">HNSW</a><ul>
                        
                <li>
                    <a href="#%e6%a6%82%e8%a7%88-1" aria-label="概览">概览</a></li>
                <li>
                    <a href="#%e7%ae%97%e6%b3%95%e4%bb%8b%e7%bb%8d-1" aria-label="算法介绍">算法介绍</a><ul>
                        
                <li>
                    <a href="#nsw--hnsw%e7%9a%84%e8%b5%b7%e6%ba%90" aria-label="NSW —— HNSW的起源?">NSW —— HNSW的起源?</a><ul>
                        
                <li>
                    <a href="#nsw%e7%9a%84%e6%9e%84%e5%bb%ba" aria-label="NSW的构建">NSW的构建</a></li>
                <li>
                    <a href="#nsw%e7%9a%84%e6%90%9c%e7%b4%a2" aria-label="NSW的搜索">NSW的搜索</a></li></ul>
                </li>
                <li>
                    <a href="#hnsw--nsw%e7%9a%84%e8%bf%9b%e5%8c%96" aria-label="HNSW —— NSW的进化">HNSW —— NSW的进化</a></li></ul>
                </li>
                <li>
                    <a href="#pgvector%e4%b8%ad%e7%9a%84%e7%ae%97%e6%b3%95%e5%ae%9e%e7%8e%b0" aria-label="PGVECTOR中的算法实现">PGVECTOR中的算法实现</a><ul>
                        
                <li>
                    <a href="#insert" aria-label="INSERT">INSERT</a></li>
                <li>
                    <a href="#search-layer" aria-label="search layer">search layer</a><ul>
                        
                <li>
                    <a href="#pairing-heap" aria-label="pairing heap">pairing heap</a></li></ul>
                </li>
                <li>
                    <a href="#select-neighbors" aria-label="select neighbors">select neighbors</a></li>
                <li>
                    <a href="#data-structure" aria-label="data structure">data structure</a><ul>
                        
                <li>
                    <a href="#%e5%ba%95%e5%b1%82%e5%ae%9e%e7%8e%b0%e4%b8%ad%e7%9a%84%e9%97%ae%e9%a2%98" aria-label="底层实现中的问题">底层实现中的问题</a></li></ul>
                </li></ul>
                </li>
                <li>
                    <a href="#page-representation-1" aria-label="page representation">page representation</a></li></ul>
                </li>
                <li>
                    <a href="#vector-database-%e8%b0%83%e7%a0%94" aria-label="vector database 调研">vector database 调研</a><ul>
                        
                <li>
                    <a href="#qdrant" aria-label="qdrant">qdrant</a><ul>
                        
                <li>
                    <a href="#%e7%ae%97%e6%b3%95%e4%b8%8e%e5%ad%98%e5%82%a8" aria-label="算法与存储">算法与存储</a></li></ul>
                </li></ul>
                </li>
                <li>
                    <a href="#%e9%99%84%e5%bd%95" aria-label="附录">附录</a><ul>
                        
                <li>
                    <a href="#trianlge-inequality-kmeans" aria-label="trianlge-inequality-Kmeans">trianlge-inequality-Kmeans</a></li>
                <li>
                    <a href="#%e9%87%87%e6%a0%b7%e7%ae%97%e6%b3%95-knuths-algorithm-s" aria-label="采样算法 Knuth&rsquo;s algorithm S">采样算法 Knuth&rsquo;s algorithm S</a></li></ul>
                </li>
                <li>
                    <a href="#%e5%90%8e%e8%ae%b0" aria-label="后记">后记</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h2 id="序言">序言<a hidden class="anchor" aria-hidden="true" href="#序言">#</a></h2>
<p><code>pgvector</code>是一个向量搜索（根据近似度）的插件，用来加速AKNN（approximate nearest neighbor）。
<code>PASE</code>中提到，向量ANN算法包括4类</p>
<ol>
<li>tree-based algorithms
<ol>
<li>KD-Tree</li>
<li>RTree</li>
</ol>
</li>
<li>quantization-based algorithms
<ol>
<li>IVFFlat</li>
<li>IVFADC</li>
<li>IMI</li>
</ol>
</li>
<li>graph based algorithms
<ol>
<li>HNSW</li>
<li>NSG</li>
<li>SSG</li>
</ol>
</li>
<li>hash-base algorithms
<ol>
<li>LSH
<code>pgvector</code> 包括两个算法，<code>IVFFlat</code> 和 <code>HNSW</code>，后续内容将以这两个算法的内容及其实现展开。</li>
</ol>
</li>
</ol>
<h2 id="ivfflat">IVFFlat<a hidden class="anchor" aria-hidden="true" href="#ivfflat">#</a></h2>
<h3 id="概览">概览<a hidden class="anchor" aria-hidden="true" href="#概览">#</a></h3>
<p>IVFFlat 算法主要包括以下几个步骤</p>
<ul>
<li>索引构建阶段
<ul>
<li>使用 <code>KMeans</code> 将数据集划分成多个簇(cluster)</li>
</ul>
</li>
<li>查询阶段
<ul>
<li>通过每个簇的中心点（向量是高维的点）获取N个最近的簇</li>
<li>遍历这N个簇的所有点，从中找到最近的K个点</li>
</ul>
</li>
</ul>
<h3 id="算法介绍">算法介绍<a hidden class="anchor" aria-hidden="true" href="#算法介绍">#</a></h3>
<h4 id="基础算法kmeans">基础算法kmeans<a hidden class="anchor" aria-hidden="true" href="#基础算法kmeans">#</a></h4>
<p>reference <a href="https://en.wikipedia.org/wiki/K-means_clustering">k-means clustering - Wikipedia</a>
算法目标：选取K个中心点，使得数据集中的所有点到其最近的中心点“距离”之和最近，以平方和距离为例：</p>
<p>Given a set of observations $(x_1, x_2, \dots, x_n)$, where each observation is a $d$-dimensional real vector, k-means clustering aims to partition the $n$ observations into $k$ ($\leq n$) sets $S = {S_1, S_2, \dot, S_k}$ so as to minimize the within-cluster sum of squares (WCSS). Formally, the objective is to find:
<img loading="lazy" src="https://raw.githubusercontent.com/mobilephone724/blog_pictures/master/kmeans_target.2024_02_12_1707672348.png">
算法过程：
<strong>我们可以很容易的证明目标函数是关于$S$的凸函数</strong>
Given an initial set of $k$ means $m_1^{1}, \dots , m_k^{(1)}$ (see below), the algorithm proceeds by alternating between two steps:</p>
<ol>
<li>
<p><strong>Assignment step</strong>: Assign each observation to the cluster with the nearest mean: <img loading="lazy" src="https://raw.githubusercontent.com/mobilephone724/blog_pictures/master/kmean_assign_step.2024_02_12_1707672359.png"></p>
<p>where each $x_p$is assigned to exactly one $S^{t}$, even if it could be assigned to two or more of them.</p>
</li>
<li>
<p><strong>Update step</strong>: Recalculate means (<a href="https://en.wikipedia.org/wiki/Centroids" title="Centroids">centroids</a>) for observations assigned to each cluster.<img loading="lazy" src="https://raw.githubusercontent.com/mobilephone724/blog_pictures/master/kmeans_update_step.2024_02_12_1707672369.png"></p>
</li>
</ol>
<h4 id="kmeans-优化篇">kmeans 优化篇<a hidden class="anchor" aria-hidden="true" href="#kmeans-优化篇">#</a></h4>
<p>上述算法虽然简洁，但计算上复杂度高。在pgvector的IVFFlat实现中，使用了一些优化算法，主要是如下两篇论文：</p>
<ul>
<li>Using Triangle Inequality: 使用三角不等式减少两点间距离的计算次数</li>
<li>KMeans++ :使用随机点的选取技巧来提高收敛速度和准确率
<a href="https://cdn.aaai.org/ICML/2003/ICML03-022.pdf">Using the Triangle Inequality to Accelerate k-Means (aaai.org)</a>
<a href="https://theory.stanford.edu/~sergei/papers/kMeansPP-soda.pdf">kMeansPP-soda.pdf (stanford.edu)</a></li>
</ul>
<h5 id="using-triangle-inequality">Using Triangle Inequality<a hidden class="anchor" aria-hidden="true" href="#using-triangle-inequality">#</a></h5>
<p>思路：</p>
<ol>
<li>在高维向量中，计算一次两点之间的距离的代价较高。</li>
<li>根据一些朴素的思想，假如使用的距离函数满足三角不等式$d(a,b) \leq d(a,c) + d(b,c)$，那么在一次<code>kmeams</code>迭代中，如果点 <code>x</code> 距其中心点 <code>c(x)</code> 的距离很近，而 <code>c(x)</code> 距另一个中心点 <code>c(y)</code> 的距离很远，那么<code>c(y)</code>必然不是<code>x</code> 的中心点，这样就可以避免一次计算。</li>
</ol>
<p>根据三角不等式可以推出</p>
<ol>
<li>Let <code>x</code> be a point and let <code>b</code> and <code>c</code> be centers. If $d(b, c) &gt; 2d(x,b)$, then $d(x,c) \geq d(x,b)$</li>
<li>Let <code>x</code> be a point and let <code>b</code> and <code>c</code> be centers, then $d(x,c) \geq \mathrm{max} {0,d(x,b)-d(b,c)}$</li>
</ol>
<p>根据上述定理，在Kmeans迭代期间，维护一些状态，即可减少计算量
过程如</p>
<p><a href="/article/pgvector/#trianlge-inequality-Kmeans">使用三角不等式优化Kmeans</a></p>
<h5 id="kmeans">KMeans++<a hidden class="anchor" aria-hidden="true" href="#kmeans">#</a></h5>
<p>论文中的数学分析很多，其主要目的为：通过在初始化的时候选取恰当的中心点，减少迭代次数。方法为：
假设向量的全集为$X={x_1,x_2,\dots,x_n}\subset \mathbb{R}^d$  ,$D(x)$ 表示点 $x$ 到其当前中心点的距离</p>
<ol>
<li>从$X$ 中随机选择一个点$c_1$</li>
<li>以$\frac{D(x&rsquo;)}{\sum_{x\in X}D(x)}$ 的概率选择$x&rsquo;$为$c_i$</li>
<li>重复上一步直到我们选择了 $k$ 个中心点，</li>
<li>使用标准的k-means算法进行后续处理</li>
</ol>
<h3 id="实现介绍">实现介绍<a hidden class="anchor" aria-hidden="true" href="#实现介绍">#</a></h3>
<h5 id="page-representation">page representation<a hidden class="anchor" aria-hidden="true" href="#page-representation">#</a></h5>
<p><img loading="lazy" src="https://raw.githubusercontent.com/mobilephone724/blog_pictures/master/IVF-pages-represent.2024_02_12_1707672384.png"></p>
<h4 id="key-functions">Key functions<a hidden class="anchor" aria-hidden="true" href="#key-functions">#</a></h4>
<h5 id="index-build">index build<a hidden class="anchor" aria-hidden="true" href="#index-build">#</a></h5>
<p>索引构建分为以下几个步骤</p>
<ol>
<li>计算中心点</li>
<li>构建元信息页（&lsquo;meta page&rsquo;）</li>
<li>构建中心点页（&lsquo;centerid pages&rsquo;）</li>
<li>构建数据页（&lsquo;data pages&rsquo;）</li>
</ol>
<pre tabindex="0"><code>ivfflatbuild
	BuildIndex
		InitBuildState
		ComputeCenters
		CreateMetaPage
		CreateListPages
		CreateEntryPages
		FreeBuildState
</code></pre><h6 id="计算中心点">计算中心点<a hidden class="anchor" aria-hidden="true" href="#计算中心点">#</a></h6>
<ol>
<li>实现上，没有扫描所有的行以计算中心点，而是“采样”一些<code>block</code>。
<ol>
<li>会选择$ncenter \times 50$ 作为采样<code>block</code>的数量</li>
<li></li>
</ol>
</li>
</ol>
<pre tabindex="0"><code>ComputeCenters
	SampleRows
		/* The number of target samples is the number of centers times 50 */
		numSamples = buildstate-&gt;lists * 50;
		buildstate-&gt;samples = VectorArrayInit(numSamples, buildstate-&gt;dimensions);
		BlockSampler_Init
			&gt; provides algorithm for block level sampling of a relation as discussed on
			  pgsql-hackers 2004-04-02 (subject &#34;Large DB&#34;)
			  Since we know the total number of blocks in advance, we can use the straightforward
			  Algorithm S from Knuth 3.4.2, rather than Vitter&#39;s algorithm.
		reservoir_init_selection_state
		while (BlockSampler_HasMore(&amp;buildstate-&gt;bs))
		table_index_build_range_scan: callback=SampleCallback
	IvfflatKmeans # Do as kmeans algrithm
    	if (samples-&gt;length &lt;= centers-&gt;maxlen)
            QuickCenters(index, samples, centers);
        else
    		ElkanKmeans(index, samples, centers);

SampleCallback
	AddSample
		if (samples-&gt;length &lt; targsamples)
			VectorArraySet
		else
			if (buildstate-&gt;rowstoskip &lt; 0)
				rowstoskip = reservoir_get_next_S #skip some future samples
			else
				k = sampler_random_fract
				VectorArraySet	# replace a old with this one randomly
</code></pre><h6 id="构建元信息页">构建元信息页<a hidden class="anchor" aria-hidden="true" href="#构建元信息页">#</a></h6>
<pre tabindex="0"><code>CreateMetaPage # info about meta information
	IvfflatNewBuffer
	IvfflatInitRegisterPage
	IvfflatCommitBuffer
</code></pre><h6 id="构建中心点页">构建中心点页<a hidden class="anchor" aria-hidden="true" href="#构建中心点页">#</a></h6>
<p>当一个页的剩余空间不够时，使用字段<code>nextblkno</code>指向下一个页</p>
<pre tabindex="0"><code>typedef struct IvfflatPageOpaqueData
{
	BlockNumber nextblkno;
	uint16		unused;
	uint16		page_id;		/* for identification of IVFFlat indexes */
}			IvfflatPageOpaqueData;


CreateListPages # info about center infomation
	foreach sampled vector
		if (PageGetFreeSpace &lt; listSize) # we need more free space to store the vector 
			IvfflatAppendPage
				newbuf = IvfflatNewBuffer
				newpage = GenericXLogRegisterBuffer
				IvfflatPageGetOpaque
				old_page-&gt;next = this_page
				IvfflatInitPage
		PageAddItem # copy this point to the page
</code></pre><h6 id="构建数据页">构建数据页<a hidden class="anchor" aria-hidden="true" href="#构建数据页">#</a></h6>
<pre tabindex="0"><code>CreateEntryPages # omit parallel optimization here
	AssignTuples # Scan table for tuples to index
	tuplesort_performsort
	InsertTuples
		for (int i = 0; i &lt; buildstate-&gt;centers-&gt;length; i++)
    		buf = IvfflatNewBuffer(index, forkNum); # add new page for each data page list
    		startPage = BufferGetBlockNumber(buf);  # the first page number
    		foreach tuple in this list:
                if (PageGetFreeSpace(page) &lt; itemsz) # append page
    				IvfflatAppendPage(index, &amp;buf, &amp;page, &amp;state, forkNum);
        		PageAddItem()
        	IvfflatUpdateList(); # update the first page record of the center page
</code></pre><h5 id="index-scan">index scan<a hidden class="anchor" aria-hidden="true" href="#index-scan">#</a></h5>
<h6 id="begin-scan">begin scan<a hidden class="anchor" aria-hidden="true" href="#begin-scan">#</a></h6>
<pre tabindex="0"><code>ivfflatbeginscan
    IvfflatGetMetaPageInfo(index, &amp;lists, &amp;dimensions);  # Get lists and dimensions from metapage
    
</code></pre><h6 id="get-tupele">get tupele<a hidden class="anchor" aria-hidden="true" href="#get-tupele">#</a></h6>
<pre tabindex="0"><code>ivfflatgettuple
    if (first) # try to get the first tuple
        GetScanLists # find &#39;probe&#39; centers that are closest
            while (BlockNumberIsValid(nextblkno)) # search all list pages
                if (distance &lt; maxDistance) # omit probe here for easier understanding
                    scanlist = (IvfflatScanList *) pairingheap_remove_first(so-&gt;listQueue);
                    pairingheap_add(so-&gt;listQueue, &amp;scanlist-&gt;ph_node);
                    maxDistance = ((IvfflatScanList *) pairingheap_first(so-&gt;listQueue))-&gt;distance;
        GetScanItems # find closest items in the above centers
            while (!pairingheap_is_empty(so-&gt;listQueue)) # for each center
                while (BlockNumberIsValid(searchPage)) # for each block in the data list
                    foreach (tuple)
                        tuplesort_puttupleslot
                    
</code></pre><h2 id="hnsw">HNSW<a hidden class="anchor" aria-hidden="true" href="#hnsw">#</a></h2>
<h3 id="概览-1">概览<a hidden class="anchor" aria-hidden="true" href="#概览-1">#</a></h3>
<p>HNSW 算法主要包括以下几个步骤</p>
<ul>
<li>索引构建
<ul>
<li>构建层级邻近图
<ul>
<li>每一层都是邻近图 —— 每个点都记录它最近的几个点</li>
<li>高一层的图是低一层图的缩略图 —— 只有低一层图的部分点 ——，最低一层的图有全部点的信息。</li>
</ul>
</li>
</ul>
</li>
<li>查询阶段，对于目标点$p$
<ul>
<li>对于每一层图：
<ul>
<li>维护一个图中距点$p$最近的点集合$S$，依次从候选点集合$C$中选取一个元素$c$：如果$c$的邻居$neighbor(c)$比$S$中距$p$最远的点$s$距$p$更近，即$d(neighbor(c), p) &lt; d(s,c)$ ，则用$neighbor(c)$替换集合$S$中的点$s$，并将$s$加入到候选集合$C$中。重复以上步骤直到$|c| = 0$</li>
</ul>
</li>
<li>从高层图向底层图搜索，使用高层图的结果$S$作为低层图$S$和$C$的初始值。</li>
</ul>
</li>
</ul>
<p><img loading="lazy" src="https://raw.githubusercontent.com/mobilephone724/blog_pictures/master/illustration-of-HNSW.2024_02_12_1707672400.png"></p>
<h3 id="算法介绍-1">算法介绍<a hidden class="anchor" aria-hidden="true" href="#算法介绍-1">#</a></h3>
<p>一下顺序只是为了便于理解，不代表论文发布顺序。更多细节可参考论文。</p>
<h4 id="nsw--hnsw的起源">NSW —— HNSW的起源?<a hidden class="anchor" aria-hidden="true" href="#nsw--hnsw的起源">#</a></h4>
<p>NSW可以视为邻近图，每个点维护至多$K$个距离其最近的点，此时HNSW退化为只有一层的特殊情况。</p>
<h5 id="nsw的构建">NSW的构建<a hidden class="anchor" aria-hidden="true" href="#nsw的构建">#</a></h5>
<p>构建NSW的算法如下（此处忽略边角情况以方便理解</p>
<pre tabindex="0"><code>INPUT: a set of points S
OUTPUT: graph G
BUILD_LAYER(S)

G = []
# Insert each point into the graph
FOREACH point IN S:           ---------- INSERT_POINT(graph, point)
    neighbors[] = select_one_random(G)
    candidate[] = neighbors[]
    visited_points[] = neighbors[]

    # Code in this WHILE loop is to find the neighbors of the point
    # in current graph
    WHILE (!candidate.empty())
        nearest_candidate = candidate.pop_nearest(point)
        furthest_neighbor = neighbors.get_furthest(point)

        # no candidate can b closer
        IF (distant(nearest_candidate, point) &gt;
            distant(furthest_neighbor, point))
            break;

        # This candidate is great, but what about its neighbors?
        FOREACH candidate_neighbor in nearest_candidate.neighbors()
            IF (visited_points.has(candidate_neighbor))
                continue
            visited_points.append(candidate_neighbor)

            # the furthest one can be changed
            furthest_neighbor = neighbors.get_furthest(point)

            # The neighbor of this candidate is also great, its neighbors
            # can also be candidates
            IF (distant(candidate_neighbor, point) &lt;
                distant(furthest_neighbor, point))
                candidate.append(candidate_neighbor)
                neighbors.append(candidate_neighbor)
                IF (neighbors.size() &gt; MAX_NEIGHBORS)
                    neighbors.pop_furthest(point)

    # Now we have found the neighbors, add a bidirection connections
    # between the each neighbor and the point
    FOREACH this_neighbor in neighbors
        add_bidirection_direction(this_neighbor, point)

        # Since the neighbor has one more connection, we may need
        # to shrink. This is a point to optimize. Read paper for detail.
        IF this_neighbor.neighbors().size() &gt; MAX_NEIGHBORS
            this_neighbor.drop_longest_connection()

# All points have been added
RETURN G
</code></pre><h5 id="nsw的搜索">NSW的搜索<a hidden class="anchor" aria-hidden="true" href="#nsw的搜索">#</a></h5>
<pre tabindex="0"><code>OUTPUT: graph G, point P
RETURN K nearest neighbors
SEARCH_LAYER(G, p, K)

candidates = select_one_random(G)
visited_points = candidates

# LOOP until we have K stable points
WHILE TRUE
    candidates_old = candidates

    FOREACH candidate in candidates
        FOREACH neighbor in candidate.neighbors()
            if (visited_points.has(neighbor))
                continue
            visited_points.add(neighbor)

            furthest_candidate = candidates.get_furthest(point)
            IF (distant(neighbor, P) &lt; distant(furthest_candidate, P) ||
                candidates.size() &lt; K)
                candidates.add(neighbor)
            IF (candidates.size() &gt; K)
                candidates.pop_furthest(P)

    IF candidates_old == candidates
        BREAK

RETURN candidates
</code></pre><h4 id="hnsw--nsw的进化">HNSW —— NSW的进化<a hidden class="anchor" aria-hidden="true" href="#hnsw--nsw的进化">#</a></h4>
<p>显然，上述过程最大的问题之一为：</p>
<ol>
<li>对于图的构建：每新加入一个点，都需要从一个随机点开始搜索它的邻居。</li>
<li>对于图的搜索：需要从一个随机点开始搜索。
以上两点导致，NSW算法搜索了很多无用的点。
H(hierarchy)NSW 为解决这个问题，从NSW图（layer=0）中选出部分点，再构建一个缩略的NSW图（layer=1）。在搜索的时候，只需要从layer=1的图中搜索出一个粗略结果，将该结果用于layer=0搜索过程中的初始化，即可大量减少无用的搜索。同理，层数也不一定只有2层，可以有更多。
（这个思想在科研中似乎经常使用:先得出一个粗略的结果，再进一步精细化）</li>
</ol>
<p>为了构建一个这样的图，我们在插入一个点时。</p>
<pre tabindex="0"><code>INPUT: point P, a series of NSW graph G[]

cur_layer = -ln(unif(0, 1)) * MAX_LAYER

# for layer upper than current layer, just get a candidate
FOR l from MAX_LAYER to cur_layer + 1
    closest_points = SEARCH_LAYER(G[l], P, 1, candidates = closest_point)

# insert into each layer from top to bottom of the below layers
FOR l from cur_layer to 0
    closest_points = SEARCH_LAYER(G[l], P, 1, candidates = closest_points)
    INSERT_POINT(graph, P, neighbors = closest_points)
</code></pre><p>同理在搜索时</p>
<pre tabindex="0"><code>INPUT: point P, a series of NSW graph G[]

cur_layer = P.layer

# for layer upper than current layer, just get a candidate
FOR l from MAX_LAYER to cur_layer + 1
    closest_points = SEARCH_LAYER(G[l], P, 1, candidates = closest_point)

# for layer leq than current layer, just get a candidate
FOR l from cur_layer to 0
    closest_points = SEARCH_LAYER(G[l], P, 1, candidates = closest_point)

return closest_points
</code></pre><h3 id="pgvector中的算法实现">PGVECTOR中的算法实现<a hidden class="anchor" aria-hidden="true" href="#pgvector中的算法实现">#</a></h3>
<h4 id="insert">INSERT<a hidden class="anchor" aria-hidden="true" href="#insert">#</a></h4>
<p><img loading="lazy" src="https://raw.githubusercontent.com/mobilephone724/blog_pictures/master/HNSW_INSERT_ALGORITH.2024_02_12_1707672412.png"></p>
<pre tabindex="0"><code class="language-HnswInsertElement" data-lang="HnswInsertElement">/*
 * Algorithm 1 from paper: update graph by inserting an element
 * Parms:
 * @element: element to insert
 * @entryPoint: the initial entry point
 * @index?
 * @procinfo
 * @collation
 * @m: same as &#34;M&#34; in algo(number of established connections)
 */
HnswInsertElement(HnswElement element, HnswElement entryPoint,
    			  Relation index, FmgrInfo *procinfo, Oid collation,
    			  int m, int efConstruction, bool existing)
    level = element-&gt;level;
    q = PointerGetDatum(element-&gt;vec)

    # fill entry point list with the initial one
    ep = list_make1(HnswEntryCandidate(entryPoint,))

    # for layers upper than the element&#39;s level
    for (int lc = entryLevel; lc &gt;= level + 1; lc--)
        # only get the nearest element now
        w = HnswSearchLayer()
        ep = w;

    # for the below layers
    for (int lc = level; lc &gt;= 0; lc)
        # search for top efConstruction nearest ones
        w = HnswSearchLayer(efConstruction)

        lw = w

        # get neighbors
        neighbors = SelectNeighbors(lw, lm, lc, procinfo, collation, NULL);

        # add connection
        # Is this different from paper?
        #  bidirectional vs single directional
        #  shrink directions or not shrink
        AddConnections()
            foreach(lc2, neighbors)
        		a-&gt;items[a-&gt;length++] = *((HnswCandidate *) lfirst(lc2));
</code></pre><h4 id="search-layer">search layer<a hidden class="anchor" aria-hidden="true" href="#search-layer">#</a></h4>
<p><img loading="lazy" src="https://raw.githubusercontent.com/mobilephone724/blog_pictures/master/HNSW_SEARCH_LAYER_ALGORITHM.2024_02_12_1707672421.png"></p>
<pre tabindex="0"><code>/*
 * Algorithm 2 from paper: search this layer with specifiyed enter points to
 * return &#34;ef&#34; closest neighbors
 * Parms:
 *  @q: same as algo
 *  @ep: enter points
 *  @ef: count of closest neighbors
 *  @lc: layer number
 *  @index:
 *  @procinfo:
 *  @collation:
 *  @inserting:
 *  @skipElement:
 */
List *
HnswSearchLayer(Datum q, List *ep, int ef, int lc, Relation index,
                FmgrInfo *procinfo, Oid collation, int m, bool inserting,
                HnswElement skipElement)
    v = NULL.                 # visited points
    C = NULL                  # set of candidates, nearer first
    W = NULL                  # dynamic found nearest neighbors

    # for each candidate in enter points
    foreach(lc2, ep)
        hc = (HnswCandidate *) lfirst(lc2); # HNSW candidates
        v.add(hc)
        C.add(hc)
        W.add(hc)

    # loop until no more candidates
    while (!C.empty())
        c = C.pop_nearest()

        # for each neighbor &#34;e&#34; in the nearest candicate &#34;c&#34;
        neighborhood = &amp;c-&gt;element-&gt;neighbors[lc];
        for (int i = 0; i &lt; neighborhood-&gt;length; i++)
            # neighbor e
            HnswCandidate *e = &amp;neighborhood-&gt;items[i];
            v.add(e)
            DO # continue if visited

            # f is the furthest element in dynamic neighbors
            f = W.furthest()

            # find a good neighbor who is closer to q than the worst one in W
            if (DISTANT(e, q) &lt; DISTANT(f, q) || wlen &lt; ef)
                ec = e
                # neighbor of ec can also be the candidates
                C.add(ec)
                # add ec to W to promote the lower bound
                W.add(ec)

                # clean W if it&#39;s too large
                if (skipElement == NULL ||
                    list_length(e-&gt;element-&gt;heaptids) != 0)
					wlen++;
					/* No need to decrement wlen */
					if (wlen &gt; ef)
						W.pop_furthest
	return W
</code></pre><h5 id="pairing-heap">pairing heap<a hidden class="anchor" aria-hidden="true" href="#pairing-heap">#</a></h5>
<p><a href="https://oi-wiki.org/ds/pairing-heap/">配对堆 - OI Wiki (oi-wiki.org)</a></p>
<ul>
<li>insert($\mathrm{log}n$)</li>
<li>random_select($\mathrm{log} n$) select_min($\mathrm{log} n$)</li>
<li>delete_min($\mathrm{log} n$)</li>
</ul>
<h4 id="select-neighbors">select neighbors<a hidden class="anchor" aria-hidden="true" href="#select-neighbors">#</a></h4>
<p><img loading="lazy" src="https://raw.githubusercontent.com/mobilephone724/blog_pictures/master/HNSW_SELECT_NEIGHBORS_ALGORITHMS.2024_02_12_1707672431.png"></p>
<pre tabindex="0"><code class="language-SelectNeighbors" data-lang="SelectNeighbors">/*
 * Algorithm 4: select neighbors starting with specified candidates
 * PARAMS:
 *  @c : candidates
 *  @m : number of neighbors to return
 *  @lc: layer number
 *  @
 *
 * NOTES:
 *  extendCandidates = false
 *  keepPrunedConnections = true
 *  pruned
 */
static List *
SelectNeighbors(List *c, int m, int lc, FmgrInfo *procinfo, Oid collation,
                HnswCandidate * *pruned)
    r = NULL    # results---returning neighbors 
    w = c       # working candidates
    wd = NULL;  # discarded candidates;

    # Since we don&#39;t extend candidates, if the starting candidates isn&#39;t enought
    # just return.
    if (list_length(w) &lt;= m)
        return w

    # loop untils no more working candidate or enought neighbors
    while (length(w) &gt; 0 &amp;&amp; length(r) &lt; m)
        *e = llast(w); # get the nearest candidates
        closer = CheckElementCloser(e, r, lc, procinfo, collation);
        if(closer)
            r.append(e)
        else
            wd.append(e)

    # loop until discarded candidates are empty or enough neighbors
    while (!wd.empty() &amp;&amp; length(r) &lt; m)
        r.append(wd.pop_nearest())
    
    prune = wd.nearest()
    return r
    
    
</code></pre><h4 id="data-structure">data structure<a hidden class="anchor" aria-hidden="true" href="#data-structure">#</a></h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-c" data-lang="c"><span class="line"><span class="cl"><span class="k">typedef</span> <span class="k">struct</span> <span class="n">HnswElementData</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">	<span class="n">List</span>	   <span class="o">*</span><span class="n">heaptids</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">	<span class="n">uint8</span>		<span class="n">level</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">	<span class="n">uint8</span>		<span class="n">deleted</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">	<span class="n">HnswNeighborArray</span> <span class="o">*</span><span class="n">neighbors</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">	<span class="n">BlockNumber</span> <span class="n">blkno</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">	<span class="n">OffsetNumber</span> <span class="n">offno</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">	<span class="n">OffsetNumber</span> <span class="n">neighborOffno</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">	<span class="n">BlockNumber</span> <span class="n">neighborPage</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">	<span class="n">Vector</span>	   <span class="o">*</span><span class="n">vec</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>			<span class="n">HnswElementData</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">typedef</span> <span class="k">struct</span> <span class="n">HnswCandidate</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">	<span class="n">HnswElement</span> <span class="n">element</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">	<span class="kt">float</span>		<span class="n">distance</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>			<span class="n">HnswCandidate</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">typedef</span> <span class="k">struct</span> <span class="n">HnswNeighborArray</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">	<span class="kt">int</span>			<span class="n">length</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">	<span class="n">HnswCandidate</span> <span class="o">*</span><span class="n">items</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>			<span class="n">HnswNeighborArray</span><span class="p">;</span>
</span></span></code></pre></div><h5 id="底层实现中的问题">底层实现中的问题<a hidden class="anchor" aria-hidden="true" href="#底层实现中的问题">#</a></h5>
<ol>
<li>论文中的图是双向连接，而pgvector实现的是单向连接</li>
<li>pgvector中插入新向量时，没有更新其邻居的连接。（这么低级的问题有待验证）</li>
</ol>
<h3 id="page-representation-1">page representation<a hidden class="anchor" aria-hidden="true" href="#page-representation-1">#</a></h3>
<p><img alt="image-20231007080940352" loading="lazy" src="https://raw.githubusercontent.com/mobilephone724/blog_pictures/master/HNSW_PAGE_REPRESENTATION.2024_02_12_1707672445.png">
<img loading="lazy" src="https://raw.githubusercontent.com/mobilephone724/blog_pictures/master/PGVEC-HNSW-PAGE.2024_02_12_1707672457.png"></p>
<h2 id="vector-database-调研">vector database 调研<a hidden class="anchor" aria-hidden="true" href="#vector-database-调研">#</a></h2>
<h3 id="qdrant">qdrant<a hidden class="anchor" aria-hidden="true" href="#qdrant">#</a></h3>
<p><img alt="image-20231007080940352" loading="lazy" src="https://raw.githubusercontent.com/mobilephone724/blog_pictures/master/vector-database.2024_02_12_1707672561.png"></p>
<blockquote>
<p>Vector databases are optimized for <strong>storing</strong> and <strong>querying</strong> these high-dimensional vectors efficiently, and they often using specialized data structures and indexing techniques such as Hierarchical Navigable Small World (HNSW) – which is used to implement Approximate Nearest Neighbors – and Product Quantization, among others.</p>
</blockquote>
<p><img alt="image-20231007081700863" loading="lazy" src="https://raw.githubusercontent.com/mobilephone724/blog_pictures/master/image-20231007081700863.2024_02_12_1707672473.png"></p>
<h4 id="算法与存储">算法与存储<a hidden class="anchor" aria-hidden="true" href="#算法与存储">#</a></h4>
<p>qdrant使用 <code>hnsw</code> 算法</p>
<blockquote>
<p>A key feature of Qdrant is the effective combination of <strong>vector</strong> and <strong>traditional</strong> indexes. It is essential to have this because for vector search to work effectively with filters, having vector index only is not enough. In simpler terms, a vector index speeds up vector search, and payload indexes speed up filtering.</p>
</blockquote>
<p>payload 索引仅用于过滤，我们关注向量索引部分</p>
<blockquote>
<p>Qdrant currently only uses HNSW as a vector index.</p>
</blockquote>
<blockquote>
<p>All data within one collection is divided into segments. Each segment has its independent vector and payload storage as well as indexes.</p>
</blockquote>
<h2 id="附录">附录<a hidden class="anchor" aria-hidden="true" href="#附录">#</a></h2>
<h3 id="trianlge-inequality-kmeans">trianlge-inequality-Kmeans<a hidden class="anchor" aria-hidden="true" href="#trianlge-inequality-kmeans">#</a></h3>
<ul>
<li>维护的状态：
<ul>
<li>lower bound $l(x,c)$ of $d(x,c)$ for each point $x$ and center $c$
<ul>
<li>each time $d(x,c)$ is computed, set $l(x,c)=d(x,c)$</li>
</ul>
</li>
<li>$c(x)= \mathrm{argmin}_cd(x,c)$ get its center for each point $x$</li>
<li>upper bound $u(x)$ of $d(x,c)$ for each point $x$, indicating the upper bound of $x$ to its center</li>
<li>$r(x)$ is a <code>boolean</code> value indicate whether $u(x, c)$ is out of date</li>
</ul>
</li>
<li>过程：
<ul>
<li>initialization
<ul>
<li>compute $d(x,c)$ for each point $x$ and each center $c$, which means $l(x,c)$ is computed too</li>
<li>$u(x)=\mathrm{min}_c(d,c)$ for each point $x$</li>
</ul>
</li>
<li>repeate until convergence:
<ol>
<li>For each pair of centers $c$ and $c&rsquo;$ , compute $d(c,c&rsquo;)$, this is to compute $s(c)=1/2\min_{c&rsquo;\neq c}d(c,c&rsquo;)$ . <strong>So we get the distance to the nearest center of each center</strong></li>
<li>identify all point $x$ such that $u(x) \le s(c(x))$ .<strong>If the point is so near to its center, its center can&rsquo;t be changed in this iteration. See lemma 1</strong></li>
<li>For each remaining point $x$ and centers $c$ such that
<ol>
<li>$c\neq c(x)$  (<strong>not the current center</strong>) and</li>
<li>$u(x)&gt;l(x,c)$ (<strong>upper bound to current center greater than lower bound of this center</strong>) and</li>
<li>$u(x)&gt;\frac{1}{2}d(c(x),c)$(<strong>upper bound to current center greater than half of the two centers distant, See lemma 1</strong>) <strong>iterm <code>2</code> and <code>3</code> means $u(x)$ may be too big</strong></li>
<li>DO:
<ol>
<li>If $r(x)$ , compute$d(x, c(x))$ and set $r(x)=false$, else $d(x,c(x))=u(x)$</li>
<li>if $u(x)&gt;l(x,c)$ and $u(x)&gt;\frac{1}{2}d(c(x),c)$ then (<strong>same as the above</strong>)
<ol>
<li>compute $d(x,c)$, if $d(x,c) &lt; d(x,c(x))$ then assign $c(x)=c$ (<strong>update center</strong>)</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
<li>For each center $c$ , let $m(c)$ be the new mean point</li>
<li>For each point $x$ and center $c$, assign $l(x,c)=\max{l(x,c)-d(c,m(c))}$ (<strong>update lower bound by lemma 2</strong>)</li>
<li>For each point x, assign $u(x)=u(x) + d(m(c(x)),c(x))$ (<strong>update lower bound by lemma 2</strong> ) and $r(x)=true$</li>
<li>Replace each center $c$ by $m(c)$</li>
</ol>
</li>
</ul>
</li>
</ul>
<h3 id="采样算法-knuths-algorithm-s">采样算法 Knuth&rsquo;s algorithm S<a hidden class="anchor" aria-hidden="true" href="#采样算法-knuths-algorithm-s">#</a></h3>
<ul>
<li>算法描述： Select $n$ items from a set of $M$ iems with equal probility for $M \geq n$</li>
<li>实现</li>
</ul>
<pre tabindex="0"><code>samples = set[0:n-1]
for i in (n, M)
	with prob = n/i:
    	samples[random()%n] = set[i]
</code></pre><p>参考文档 <a href="https://rosettacode.org/wiki/Knuth's_algorithm_S">Knuth&rsquo;s algorithm S - Rosetta Code</a> 。</p>
<p>社区讨论 [PostgreSQL: Re: <a href="https://www.postgresql.org/message-id/8ftr60l1ebgcable559ogr2tlb6nuujllq@email.aon.at">GENERAL] Large DB</a></p>
<h2 id="后记">后记<a hidden class="anchor" aria-hidden="true" href="#后记">#</a></h2>
<ul>
<li>pg官方的新闻：<a href="https://www.postgresql.org/about/news/pgvector-050-released-2700/">PostgreSQL: pgvector 0.5.0 Released!</a> 。pgvector在社区的热度不小</li>
</ul>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>


<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share PGVECTOR AND VECTOR DATABASE on x"
            href="https://x.com/intent/tweet/?text=PGVECTOR%20AND%20VECTOR%20DATABASE&amp;url=http%3a%2f%2flocalhost%3a1313%2farticle%2fpgvector%2f&amp;hashtags=">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share PGVECTOR AND VECTOR DATABASE on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=http%3a%2f%2flocalhost%3a1313%2farticle%2fpgvector%2f&amp;title=PGVECTOR%20AND%20VECTOR%20DATABASE&amp;summary=PGVECTOR%20AND%20VECTOR%20DATABASE&amp;source=http%3a%2f%2flocalhost%3a1313%2farticle%2fpgvector%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share PGVECTOR AND VECTOR DATABASE on reddit"
            href="https://reddit.com/submit?url=http%3a%2f%2flocalhost%3a1313%2farticle%2fpgvector%2f&title=PGVECTOR%20AND%20VECTOR%20DATABASE">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share PGVECTOR AND VECTOR DATABASE on facebook"
            href="https://facebook.com/sharer/sharer.php?u=http%3a%2f%2flocalhost%3a1313%2farticle%2fpgvector%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share PGVECTOR AND VECTOR DATABASE on whatsapp"
            href="https://api.whatsapp.com/send?text=PGVECTOR%20AND%20VECTOR%20DATABASE%20-%20http%3a%2f%2flocalhost%3a1313%2farticle%2fpgvector%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share PGVECTOR AND VECTOR DATABASE on telegram"
            href="https://telegram.me/share/url?text=PGVECTOR%20AND%20VECTOR%20DATABASE&amp;url=http%3a%2f%2flocalhost%3a1313%2farticle%2fpgvector%2f">
            <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
                <path
                    d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share PGVECTOR AND VECTOR DATABASE on ycombinator"
            href="https://news.ycombinator.com/submitlink?t=PGVECTOR%20AND%20VECTOR%20DATABASE&u=http%3a%2f%2flocalhost%3a1313%2farticle%2fpgvector%2f">
            <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
                xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
                <path
                    d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
            </svg>
        </a>
    </li>
</ul>

  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>© <a href="https://github.com/adityatelange/hugo-PaperMod/graphs/contributors">PaperMod Contributors</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
